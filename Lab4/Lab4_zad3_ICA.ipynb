{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a42d20",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.decomposition import FastICA\n",
    "from scipy.io.wavfile import read as read_wav"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6246e9f",
   "metadata": {},
   "source": [
    "1. Z bazy https://data.vision.ee.ethz.ch/cvl/ae_dataset/ pobierz i wczytaj trzy sygnały akustyczne (możesz też skorzystać z nagrań w folderze sygnaly_ICA). Dodaj je do jednej macierzy - sygnały mają różne długości, więc konieczny będzie zero-padding (może być symetryczny, ale nie musi - dobierz go tak jak chcesz; możesz też edytować sygnały w zewnętrznym programie tak, aby miały równą długość)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a1f385",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "508355bb",
   "metadata": {},
   "source": [
    "2. Zmiksuj sygnały, stosując dowolną macierz miksowania. Sygnały są rzeczywiste, więc zawierają już szum - możesz jednak dodać do któregoś z nich szum gaussowski tak jak było podane w przykładzie, aby sprawdzić, jak poradzi sobie z tym algorytm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b74bdb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "53b568f5",
   "metadata": {},
   "source": [
    "3. Zastosuj algorytm ICA do odtworzenia trzech sygnałów składowych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70acc05d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f67212d9",
   "metadata": {},
   "source": [
    "4. Wyświetl na wykresach:\n",
    "- sygnał obserwowany (zmiksowane sygnały składowe)\n",
    "- sygnały oryginalne\n",
    "- sygnały zrekonstruowane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e206487",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "533de74c",
   "metadata": {},
   "source": [
    "5. Zapisz zrekonstruowane sygnały do pliku .WAV (np. funkcją [`scipy.io.wavfile.write`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.io.wavfile.write.html))\n",
    "\n",
    "    Funkcja dobiera rozdzielczość bitową w zależności od typu danych (patrz dokumentacja). Jeżeli amplitudy są bardzo małe, to trzeba przed zapisaniem do pliku znormalizować je używając kodu poniżej (w razie potrzeby zmień nazwy zmiennych)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849eaad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io.wavfile import write as write_wav\n",
    "\n",
    "#jesli zapisujemy w formacie PCM 16:\n",
    "S_reconstructed_norm = S_reconstructed * (2 ** 15 - 1)/ np.max(np.abs(S_reconstructed), axis=0)\n",
    "# axis=0 wyznacza maksimum z każdej kolumny, nie z całej macierzy\n",
    "write_wav('reconstructed0.wav', fs, S_reconstructed_norm[:, 0].astype(np.int16))\n",
    "\n",
    "# analogicznie zapisujemy pozostałe składowe - można to zrobić w pętli\n",
    "\n",
    "\n",
    "# jesli chcemy zapisać jako PCM 32fp możemy użyć scalera:\n",
    "S_reconstructed_norm = MaxAbsScaler().fit_transform(S_reconstructed)\n",
    "write_wav('reconstructed0.wav', fs, S_reconstructed_norm[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbe0a6b",
   "metadata": {},
   "source": [
    "Alternatywnie, możesz użyć biblioteki [soundfile](https://python-soundfile.readthedocs.io/en/0.11.0/), która pozwala na zapis w formacie PCM 24 - uwaga na kolejność argumentów, jest inna niż w scipy!\n",
    "\n",
    "(Bibliotek do obsługi plików dźwiękowych w Pythonie jest ogólnie [całkiem sporo](https://nbviewer.org/github/mgeier/python-audio/blob/master/audio-files/index.ipynb) - dla nas istotne jest, aby operowały na macierzach numpy.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de4bfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "\n",
    "S_reconstructed_norm = S_reconstructed * (2 ** 23 - 1)/ np.max(np.abs(S_reconstructed), axis=0)\n",
    "sf.write('reconstructed0.wav', S_reconstructed_norm[:, 0], fs, subtype='PCM_24')\n",
    "# analogicznie dla pozostałych składowych"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde618d0",
   "metadata": {},
   "source": [
    "6. Odtwórz zapisane pliki .WAV. Możesz to zrobić w zewnętrznym programie, lub bezpośrednio w notebooku - najprościej używając widżetu iPythona:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77051260",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio, display\n",
    "\n",
    "display(Audio(filename='reconstructed0.wav')) # owinięcie w display pozwoli na odtworzenie dźwięku także, jeśli poniżej znajdzie się inny kod"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a939b86",
   "metadata": {},
   "source": [
    "7. Wyświetl zrekonstruowaną macierz miksowania. Czy jest ona taka sama jak ta, która została użyta do miksowania sygnałów oryginalnych?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314130b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
