{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W tym zadaniu przećwiczymy PCA oraz poznamy inne metody redukcji wymiarowości.\n",
    "\n",
    "W poprzednich dwóch zadaniach ekstrahowaliśmy cechy z sygnału podzielonego na ramki, uzyskując obraz (macierz 2D) opisujący sygnał. Jest to bardzo często stosowane w analizie sygnałów podejście, ale nie jedyne.\n",
    "\n",
    "Z sygnałów można też ekstrahować inne parametry, np. parametry czasowe sygnału (częstotliwość przejść przez zero, środek ciężkości sygnału), parametry widmowe (momenty widmowe, kurtoza i skośność widma), parametry formantowe (częstotliwości formantów, stosunek ich amplitud) i wiele innych. Zbiór różnych parametrów sygnałów, które dają bardzo dobre rezultaty w klasyfikacji sygnałów akustycznych jest zawarty w bibliotece [openSMILE](https://audeering.github.io/opensmile/index.html).\n",
    "\n",
    "OpenSMILE pozwala wyznaczyć predefiniowane zestawy parametrów opisujących dźwięk lub wideo - skorzystamy z zestawu 6373 parametrów opisujących pojedynczy sygnał (jest to zestaw cech i ich pochodnych używany w Interspeech Computational Paralinguistics Challenge; dla zainteresowanych opis: https://doi.org/10.3389/fpsyg.2013.00292 - tabele 2 i 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14885870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# jesli pracujemy w Colabie, konieczna jest instalacja biblioteki\n",
    "!pip install opensmile\n",
    "import opensmile\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 6373)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smile = opensmile.Smile(\n",
    "    feature_set=opensmile.FeatureSet.ComParE_2016,\n",
    "    feature_level=opensmile.FeatureLevel.Functionals,\n",
    ")\n",
    "\n",
    "feats = smile.process_file('dane_testowe/1-phrase.wav')\n",
    "feats.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wykorzystując napisany wcześniej kod, wylicz parametry wszystkich sygnałów zawartych w pliku `phrase_files.csv`. Podziel dane na zbiór treningowy i testowy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "808a02d5",
   "metadata": {},
   "source": [
    "Ze względu na zróżnicowanie parametrów, musimy przeprowadzić standaryzację:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na ustandaryzowanych danych wytrenuj używany już wcześniej klasyfikator k najbliższych sąsiadów i wylicz metryki.\n",
    "\n",
    "Warto ten krok zdefiniować jako funkcję - będziemy korzystać z niego kilka razy w tym notatniku."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6373 cechy opisujące jeden sygnał to dość dużo. Żeby zmniejszyć liczbę tych cech należy zastosować jedną z metod redukcji wymiarowości. Wpłynie to na zmniejszenie skomplikowania niektórych rodzajów klasyfikatorów, przyspieszy proces uczenia i pozwoli zmniejszyć przeuczenie modelu.\n",
    "\n",
    "Zaczniemy od metody bazującej na wartości statystyki F. W bibliotece sklearn jest to funkcja [`SelectKBest`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html?highlight=selectkbest#sklearn.feature_selection.SelectKBest).\n",
    "\n",
    "Wybierz liczbę cech, które chcesz zachować. Funkcja wybierze ze wszystkich 6373 cech tylko tyle, ile sprecyzujesz, w taki sposób, by jak najlepiej opisywać zmienność i różnicować obiekty.\n",
    "\n",
    "Liczbę cech można optymalizować, ale tym zajmiemy się kiedy indziej. Dzisiaj spróbuj ręcznie dobrać ich liczbę tak, by wyniki klasyfikacji były zadowalające."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "liczba_cech = #wpisz tu wartość\n",
    "selector = SelectKBest(k=liczba_cech)\n",
    "X_train_Kbest = selector.fit_transform(X_train)\n",
    "X_test_Kbest = selector.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wytrenuj klasyfikator na zredukowanej liczbie cech. Jakie wartości metryk wyszły teraz? Czy są lepsze czy gorsze niż wcześniej?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kolejną funkcją wartą poznania jest metoda bardzo podobna do `SelectKBest`, czyli [`SelectPercentile`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectPercentile.html#sklearn.feature_selection.SelectPercentile). Działa na tej samej zasadzie, ale zamiast określać konkretną liczbę cech, które chcemy zachować, określamy jaka część cech ma być zachowana, np. 40%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectPercentile\n",
    "\n",
    "percentile = #wpisz tu wartość\n",
    "selector = SelectPercentile(percentile=percentile)\n",
    "X_train_percent = selector.fit_transform(X_train)\n",
    "X_test_percent = selector.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ostatnią metodą, którą dzisiaj poznamy jest [rekursywna eliminacja cech](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html#sklearn.feature_selection.RFE) (RFE, ang. recursive feature elimination). Polega na tym, że estymator początkowo uczony jest na całym zbiorze danych i tworzony jest ranking cech w oparciu o to, jak bardzo są ważne podczas estymacji. Cechy najmniej istotne są usuwane i cały proces jest powtarzany. Usuwanie cech trwa tak długo, aż uzyskamy taką liczbę, jak sprecyzowana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "n_features = #wpisz tu wartość\n",
    "step = #wpisz tu wartość\n",
    "estimator = LinearRegression()\n",
    "selector = RFE(estimator, n_features_to_select=n_features, step=step) \n",
    "\"\"\"step - jeżeli >=1, to jest to liczba cech do usunięcia w danej iteracji,\n",
    "jeżeli 0<step<1 - część cech do usunięcia.\n",
    "Analogicznie działa parametr n_features_to_select\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Powtórz proces uczenia i predykcji na cechach uzyskanych metodą RFE. Jakie wartości metryk wyszły tym razem? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na koniec wykonaj PCA na cechach z openSMILE, wykorzystując kod z poprzedniego zadania. Porównaj wyniki z pozostałymi metodami."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711fedd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
