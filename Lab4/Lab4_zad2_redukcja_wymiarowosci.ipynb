{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W tym zadaniu przećwiczymy PCA oraz poznamy inne metody redukcji wymiarowości.\n",
    "\n",
    "W poprzednich dwóch zadaniach ekstrahowaliśmy cechy z sygnału podzielonego na ramki, uzyskując obraz (macierz 2D) opisujący sygnał. Jest to bardzo często stosowane w analizie sygnałów podejście, ale nie jedyne.\n",
    "\n",
    "Z sygnałów można też ekstrahować inne parametry, np. parametry czasowe sygnału (częstotliwość przejść przez zero, środek ciężkości sygnału), parametry widmowe (momenty widmowe, kurtoza i skośność widma), parametry formantowe (częstotliwości formantów, stosunek ich amplitud) i wiele innych. Zbiór różnych parametrów sygnałów, które dają bardzo dobre rezultaty w klasyfikacji sygnałów akustycznych jest zawarty w bibliotece [openSMILE](https://audeering.github.io/opensmile/index.html).\n",
    "\n",
    "OpenSMILE pozwala wyznaczyć predefiniowane zestawy parametrów opisujących dźwięk lub wideo - skorzystamy z zestawu 6373 parametrów opisujących pojedynczy sygnał (jest to zestaw cech i ich pochodnych używany w Interspeech Computational Paralinguistics Challenge; dla zainteresowanych opis: https://doi.org/10.3389/fpsyg.2013.00292 - tabele 2 i 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "14885870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# jesli pracujemy w Colabie, konieczna jest instalacja biblioteki\n",
    "# !pip install opensmile\n",
    "import opensmile\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 6373)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smile = opensmile.Smile(\n",
    "    feature_set=opensmile.FeatureSet.ComParE_2016,\n",
    "    feature_level=opensmile.FeatureLevel.Functionals,\n",
    ")\n",
    "\n",
    "feats = smile.process_file('dane_testowe/1-phrase.wav')\n",
    "feats.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wykorzystując napisany wcześniej kod, wylicz parametry wszystkich sygnałów zawartych w pliku `phrase_files.csv`. Podziel dane na zbiór treningowy i testowy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bcdfda30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 6373)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('phrase_files.csv')\n",
    "# dwa warianty odwołań do kolumny DataFrame:\n",
    "files = df.file\n",
    "y = df['label']\n",
    "\n",
    "features_list = []\n",
    "for f in files:\n",
    "    path = os.path.join('dane_testowe',f)  # dostosuj ścieżkę jeśli pliki są gdzie indziej\n",
    "    feats = smile.process_file(path)\n",
    "    features_list.append(feats)\n",
    "X = np.vstack(features_list)\n",
    "print(X.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808a02d5",
   "metadata": {},
   "source": [
    "Ze względu na zróżnicowanie parametrów, musimy przeprowadzić standaryzację:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na ustandaryzowanych danych wytrenuj używany już wcześniej klasyfikator k najbliższych sąsiadów i wylicz metryki.\n",
    "\n",
    "Warto ten krok zdefiniować jako funkcję - będziemy korzystać z niego kilka razy w tym notatniku."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 0]\n",
      " [1 1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      1.00      0.86         3\n",
      "         1.0       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.80         5\n",
      "   macro avg       0.88      0.75      0.76         5\n",
      "weighted avg       0.85      0.80      0.78         5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def knn_classification(X_train, y_train, X_test, y_test):\n",
    "    model = KNeighborsClassifier(n_neighbors=5)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    print(confusion_matrix(y_test, preds))\n",
    "    print(classification_report(y_test, preds))\n",
    "\n",
    "    return preds\n",
    "\n",
    "preds = knn_classification(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6373 cechy opisujące jeden sygnał to dość dużo. Żeby zmniejszyć liczbę tych cech należy zastosować jedną z metod redukcji wymiarowości. Wpłynie to na zmniejszenie skomplikowania niektórych rodzajów klasyfikatorów, przyspieszy proces uczenia i pozwoli zmniejszyć przeuczenie modelu.\n",
    "\n",
    "Zaczniemy od metody bazującej na wartości statystyki F. W bibliotece sklearn jest to funkcja [`SelectKBest`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html?highlight=selectkbest#sklearn.feature_selection.SelectKBest).\n",
    "\n",
    "Wybierz liczbę cech, które chcesz zachować. Funkcja wybierze ze wszystkich 6373 cech tylko tyle, ile sprecyzujesz, w taki sposób, by jak najlepiej opisywać zmienność i różnicować obiekty.\n",
    "\n",
    "Liczbę cech można optymalizować, ale tym zajmiemy się kiedy indziej. Dzisiaj spróbuj ręcznie dobrać ich liczbę tak, by wyniki klasyfikacji były zadowalające."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mfox4\\anaconda3\\envs\\pum\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [1125 1257 2156 2825 2962 3365 3520 3551 3582 3613 3644 3859 3874] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\mfox4\\anaconda3\\envs\\pum\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "liczba_cech = 100 #wpisz tu wartość\n",
    "selector = SelectKBest(k=liczba_cech)\n",
    "X_train_Kbest = selector.fit_transform(X_train, y_train)\n",
    "X_test_Kbest = selector.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wytrenuj klasyfikator na zredukowanej liczbie cech. Jakie wartości metryk wyszły teraz? Czy są lepsze czy gorsze niż wcześniej?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 0]\n",
      " [1 1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      1.00      0.86         3\n",
      "         1.0       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.80         5\n",
      "   macro avg       0.88      0.75      0.76         5\n",
      "weighted avg       0.85      0.80      0.78         5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = knn_classification(X_train_Kbest, y_train, X_test_Kbest, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kolejną funkcją wartą poznania jest metoda bardzo podobna do `SelectKBest`, czyli [`SelectPercentile`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectPercentile.html#sklearn.feature_selection.SelectPercentile). Działa na tej samej zasadzie, ale zamiast określać konkretną liczbę cech, które chcemy zachować, określamy jaka część cech ma być zachowana, np. 40%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 1]\n",
      " [0 2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.67      0.80         3\n",
      "         1.0       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.80         5\n",
      "   macro avg       0.83      0.83      0.80         5\n",
      "weighted avg       0.87      0.80      0.80         5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mfox4\\anaconda3\\envs\\pum\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:110: UserWarning: Features [1125 1257 2156 2825 2962 3365 3520 3551 3582 3613 3644 3859 3874] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\mfox4\\anaconda3\\envs\\pum\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectPercentile\n",
    "\n",
    "percentile = 20 #wpisz tu wartość\n",
    "selector = SelectPercentile(percentile=percentile)\n",
    "X_train_percent = selector.fit_transform(X_train, y_train)\n",
    "X_test_percent = selector.transform(X_test)\n",
    "\n",
    "preds = knn_classification(X_train_percent, y_train, X_test_percent, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ostatnią metodą, którą dzisiaj poznamy jest [rekursywna eliminacja cech](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html#sklearn.feature_selection.RFE) (RFE, ang. recursive feature elimination). Polega na tym, że estymator początkowo uczony jest na całym zbiorze danych i tworzony jest ranking cech w oparciu o to, jak bardzo są ważne podczas estymacji. Cechy najmniej istotne są usuwane i cały proces jest powtarzany. Usuwanie cech trwa tak długo, aż uzyskamy taką liczbę, jak sprecyzowana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "n_features = 100 #wpisz tu wartość\n",
    "step = 10 #wpisz tu wartość\n",
    "estimator = LinearRegression()\n",
    "selector = RFE(estimator, n_features_to_select=n_features, step=step) \n",
    "\"\"\"step - jeżeli >=1, to jest to liczba cech do usunięcia w danej iteracji,\n",
    "jeżeli 0<step<1 - część cech do usunięcia.\n",
    "Analogicznie działa parametr n_features_to_select\"\"\"\n",
    "selector = selector.fit(X_train, y_train)\n",
    "X_train_rfe = selector.transform(X_train)\n",
    "X_test_rfe = selector.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Powtórz proces uczenia i predykcji na cechach uzyskanych metodą RFE. Jakie wartości metryk wyszły tym razem? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 0]\n",
      " [2 0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      1.00      0.75         3\n",
      "         1.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.60         5\n",
      "   macro avg       0.30      0.50      0.38         5\n",
      "weighted avg       0.36      0.60      0.45         5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mfox4\\anaconda3\\envs\\pum\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\mfox4\\anaconda3\\envs\\pum\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\mfox4\\anaconda3\\envs\\pum\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "preds = knn_classification(X_train_rfe, y_train, X_test_rfe, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na koniec wykonaj PCA na cechach z openSMILE, wykorzystując kod z poprzedniego zadania. Porównaj wyniki z pozostałymi metodami."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "711fedd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 0]\n",
      " [2 0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      1.00      0.75         3\n",
      "         1.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.60         5\n",
      "   macro avg       0.30      0.50      0.38         5\n",
      "weighted avg       0.36      0.60      0.45         5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mfox4\\anaconda3\\envs\\pum\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\mfox4\\anaconda3\\envs\\pum\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\mfox4\\anaconda3\\envs\\pum\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=0.90)\n",
    "pca.fit(X_train)\n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "preds = knn_classification(X_train_pca, y_train, X_test_pca, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
