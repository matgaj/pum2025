{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Klasyfikacja wieloklasowa\n",
    "\n",
    "W tym zadaniu zajmiemy się problem klasyfikacji wieloklasowej. Nadal będziemy pracować na danych dotyczących rodzajów fonacji - tym razem pięciu, odpowiednio z etykietami klas:\n",
    "\n",
    "0. neutral - z nastawieniem miękkim;\n",
    "1. pressed - z nastawieniem twardym, typ I;\n",
    "2. pressedta - z nastawieniem twardym, typ II (wg autorów bazy \"while pressed vocalization was achieved by raising the larynx, pressedta was an attempt to raise the subglottal pressure directly, without raising the larynx\");\n",
    "3. breathy - z nastawieniem chuchającym;\n",
    "4. flow - \"phonation type produced with the largest peak-to-peak flow amplitude, where the minimum still reaches zero\" (miękkie nastawienie, głośniejszy, „podparty” dźwięk).\n",
    "\n",
    "W macierzy zawierającej cechy ponownie mamy 13 MFCC i ich I i II pochodną, wyznaczone dla 909 sygnałów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, make_scorer, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from optuna import create_study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip Lab6-zad2.zip\n",
    "#wczytywanie danych\n",
    "X = np.load('all_padded_features_bin.npy') # macierz cech - jednej wiersz = jeden obiekt\n",
    "y = np.load('all_labels_bin.npy') # etykiety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SVM = SVC(C=1.0, random_state=42, kernel='linear')\n",
    "SVM.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Klasyfikację wykonuje się tak samo bez względu na to, ile klas jest w zbiorze. Należy użyć metody `fit()` na zbiorze uczącym, a następnie `predict()` na zbiorze testowym.\n",
    "\n",
    "## Wyznaczanie metryk\n",
    "\n",
    "Różnica jest w obliczaniu metryk - większość z nich wymaga określenia, która klasa jest pozytywna, a która negatywna. Gdy mamy więcej niż 2 klasy, metryki wylicza się uśredniając wyniki uzyskane dla każdej z klas (zazwyczaj przy założeniu, że jest aktualnie rozpatrywana klasa jest pozytywna, a pozostałe negatywne). Trzeba określić, w jaki sposób będzie wyliczana średnia. Do wyboru mamy:\n",
    "\n",
    "- weighted - średnia ważona, najlepsza, gdy mamy nierównoliczne klasy;\n",
    "- macro - średnia arytmetyczna;\n",
    "- micro  - wynik wyznaczony globalnie poprzez zliczenie wszystkich TP, FP i FN (od razu dla całych danych, a nie dla każdej klasy z osobna).\n",
    "\n",
    "Policzmy, ile mamy obiektów w każdej z klas w zbiorze testowym, żeby wybrać sposób uśredniania przy liczeniu metryk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_ytest = np.unique(y_test, return_counts=True)\n",
    "plt.bar(counter_ytest[0].astype(int), counter_ytest[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak widać, klasy nie są równoliczne, np. klasy 3 jest prawie 2x więcej niż klasy 1. Dlatego użyjemy średniej ważonej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SVM_test_preds = SVM.predict(X_test)\n",
    "print('test accuracy = ', accuracy_score(y_test, SVM_test_preds))\n",
    "print('test F1 = ', f1_score(y_test, SVM_test_preds, average='weighted'))\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, SVM_test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Macierz pomyłek\n",
    "\n",
    "Macierz pomyłek jest dużo bardziej rozbudowana niż w przypadku klasyfikacji binarnej. Da się z niej odczytać nie tylko, które obiekty zostały zaklasyfikowane poprawnie (wartości na przekątnej), ale też sprawdzić, do której konkretnie klasy zostały przyporządkowane te, które zaklasyfikowano nieprawidłowo.\n",
    "\n",
    "Podobnie wyznaczanie krzywej ROC jest bardziej skomplikowane - można porównywać po kolei przyporządkowanie do klas parami (*one-vs-one*) lub dla każdej klasy sprawdzać klasyfikację w stosunku do wszystkich pozostałych (*one-vs-all*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie A\n",
    "\n",
    "To była klasyfikacja na danych niestandaryzowanych. Przeprowadź teraz standaryzację i klasyfikację na danych standaryzowanych (możesz utworzyć w tym celu pipeline)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "SVM.fit(X_train_scaled, y_train)\n",
    "SVM_test_preds = SVM.predict(X_test)\n",
    "\n",
    "print('scaled test accuracy = ', accuracy_score(y_test, SVM_test_preds))\n",
    "print('scaled test F1 = ', f1_score(y_test, SVM_test_preds, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie B\n",
    "\n",
    "Żeby spróbować jeszcze bardziej poprawić wyniki, poszukaj lepszych parametrów za pomocą optymalizacji lub wspomnianej w zad. 1 metody [*grid search*](https://scikit-learn.org/stable/modules/grid_search.html#grid-search). Jedyna różnica - w przypadku modeli regresyjnych i klasyfikatorów binarnych funkcją celu może być ROC AUC, natomiast w przypadku większej liczby klas trzeba wybrać inną metrykę. Najczęściej jest to czułość (*accuracy*) lub F1. Zacznijmy od F1, które teoretycznie jest lepszą metryką, bo zawiera w sobie precyzję i czułość."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = {'f1_macro': make_scorer(f1_score, average='weighted')}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zdefiniuj siatkę parametrów i przeprowadź poszukiwanie najlepszego ich zestawu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, model, get_space, X, y):\n",
    "    model_space = get_space(trial)\n",
    "\n",
    "    mdl = model(**model_space)\n",
    "    scores = cross_validate(mdl, X, y,\n",
    "                            scoring=scoring,\n",
    "                            cv=StratifiedKFold(n_splits=5),\n",
    "                            return_train_score=True)\n",
    "\n",
    "    return np.mean(scores['test_f1_macro'])\n",
    "\n",
    "def get_space(trial): \n",
    "    space = {\"C\": trial.suggest_float(\"C\", 0, 1.5), \n",
    "           'max_iter': trial.suggest_int('max_iter', 100, 100),\n",
    "           \"kernel\": trial.suggest_categorical(\"kernel\", [\"rbf\", \"linear\", \"poly\"])}\n",
    "    return space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \n",
    "trials = \n",
    "\n",
    "study = create_study(direction='maximize', study_name='multiclass_SVM_optimization')\n",
    "study.optimize(lambda x: objective(x, model, get_space, X_train_scaled, y_train), n_trials=trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dla modelu o wyznaczonych parametrach przeprowadź predykcję, oblicz dokładność, F1 i wyznacz macierz pomyłek."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trenowanie modelu o najlepszych hiperparametrach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie C\n",
    "\n",
    "Powtórz proces optymalizacji dla funkcji celu zdefiniowanej przez dokładność. Która dała lepsze wyniki? Jak bardzo udało się poprawić wyniki w porównaniu do nieoptymalizowanego modelu?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = {'acc_macro': make_scorer(accuracy_score, average='weighted')}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "colab-25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
