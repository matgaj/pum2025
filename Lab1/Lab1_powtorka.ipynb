{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skrypt zawsze zaczynamy od importu bibliotek. Te, które przydadzą się dzisiaj, są importowane poniżej.\n",
    "Użyte aliasy (`np`, `pd`, `plt`) są ogólnie przyjęte i powinno się używać takich, chociaż zdefiniowanie innych jest możliwe i w zasadzie nie jest błędem, jednak zmniejsza czytelność kodu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tables in /opt/anaconda3/envs/PUM/lib/python3.10/site-packages (3.10.1)\n",
      "Requirement already satisfied: numpy>=1.20.0 in /opt/anaconda3/envs/PUM/lib/python3.10/site-packages (from tables) (1.26.4)\n",
      "Requirement already satisfied: numexpr>=2.6.2 in /opt/anaconda3/envs/PUM/lib/python3.10/site-packages (from tables) (2.13.1)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/envs/PUM/lib/python3.10/site-packages (from tables) (25.0)\n",
      "Requirement already satisfied: py-cpuinfo in /opt/anaconda3/envs/PUM/lib/python3.10/site-packages (from tables) (9.0.0)\n",
      "Requirement already satisfied: blosc2>=2.3.0 in /opt/anaconda3/envs/PUM/lib/python3.10/site-packages (from tables) (3.9.1)\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in /opt/anaconda3/envs/PUM/lib/python3.10/site-packages (from tables) (4.15.0)\n",
      "Requirement already satisfied: ndindex in /opt/anaconda3/envs/PUM/lib/python3.10/site-packages (from blosc2>=2.3.0->tables) (1.10.0)\n",
      "Requirement already satisfied: msgpack in /opt/anaconda3/envs/PUM/lib/python3.10/site-packages (from blosc2>=2.3.0->tables) (1.1.1)\n",
      "Requirement already satisfied: platformdirs in /opt/anaconda3/envs/PUM/lib/python3.10/site-packages (from blosc2>=2.3.0->tables) (4.3.7)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/PUM/lib/python3.10/site-packages (from blosc2>=2.3.0->tables) (2.32.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/envs/PUM/lib/python3.10/site-packages (from requests->blosc2>=2.3.0->tables) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/PUM/lib/python3.10/site-packages (from requests->blosc2>=2.3.0->tables) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/PUM/lib/python3.10/site-packages (from requests->blosc2>=2.3.0->tables) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/PUM/lib/python3.10/site-packages (from requests->blosc2>=2.3.0->tables) (2025.8.3)\n"
     ]
    }
   ],
   "source": [
    "#tak można zainstalować dodatkowe biblioteki w notebooku:\n",
    "import sys\n",
    "!{sys.executable} -m pip install tables\n",
    "\n",
    "import numpy as np #podstawowe operacje numeryczne i matematyczne\n",
    "import os #interakcje z systemem operacyjnym\n",
    "import pandas as pd #analiza danych\n",
    "import pickle #zapisywanie i wczytywanie z pliku\n",
    "from pathlib import Path #łatwe manipulowanie ścieżkami\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PODSTAWY PYTHONA - POWTÓRKA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. *List comprehension* i *dictionary comprehension*\n",
    "\n",
    "Na początek przypomnimy sobie *list comprehension*, czyli pythonowy sposób tworzenia listy elementów, które są zawarte w już istniejącej liście/secie/sekwencji/generatorze i spełniają jakieś zadane kryterium. Normalnie tworzylibyśmy taką nową listę przy użyciu pętli for. *List comprehension* ma w stosunku do standardowego, \"pętlowego\", zapisu kilka zalet - przede wszystkim jest bardziej czytelny i krótszy, więc zwiększa szybkość pisania kodu. (Oczywiście nie zawsze - w przypadku pętli zagnieżdżonych, zwłaszcza wielokrotnie, *list comprehension* jest mniej czytelne i może być problematyczne w poprawnym zapisie.)\n",
    "\n",
    "Używając *list comprehension* zamiast pętli for należy stosować taki zapis:\n",
    "\n",
    "`nowa_lista = [wyrażenie for element in isteniejąca_lista]`\n",
    "\n",
    "Można również dodawać warunki:\n",
    "\n",
    "`nowa_lista = [wyrażenie for element in isteniejąca_lista if warunek]`\n",
    "\n",
    "Poniżej prosty przykład - załóżmy, że chcemy utworzyć listę liczb od 1 do 10, a następnie na jej podstawie utworzyć listę liczb parzystych i pomnożyć je przez 2. Standardowy zapis w pętli wyglądałby tak:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liczby od 1 do 10: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "Liczby parzyste x2: [4, 8, 12, 16, 20]\n"
     ]
    }
   ],
   "source": [
    "liczby = [] #deklaracja pustej listy - potrzebna do operacji append, która służy do dodawania elementu do listy\n",
    "for i in range(1,11):\n",
    "    liczby.append(i)\n",
    "print('Liczby od 1 do 10:', liczby)\n",
    "    \n",
    "parzyste = []\n",
    "for x in liczby:\n",
    "    if x%2 == 0:\n",
    "        parzyste.append(x*2)\n",
    "print('Liczby parzyste x2:', parzyste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Za pomocą *list comprehension* jest znacznie krócej:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liczby od 1 do 10: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "Liczby parzyste x2: [4, 8, 12, 16, 20]\n"
     ]
    }
   ],
   "source": [
    "liczby = list(range(1,11)) #range jest generatorem - przy wywołaniu zwraca kolejne elementy\n",
    "print('Liczby od 1 do 10:', liczby)\n",
    "\n",
    "parzyste = [x*2 for x in liczby if x%2 == 0]\n",
    "print('Liczby parzyste x2:', parzyste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operacje można też prowadzić na dwóch listach równocześnie, np."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a1', 'b2', 'c3']\n"
     ]
    }
   ],
   "source": [
    "lista1 = ['a', 'b', 'c']\n",
    "lista2 = ['1', '2', '3']\n",
    "\n",
    "suma_list = [x+y for x, y in zip(lista1, lista2)]\n",
    "print(suma_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sprawdź, co się stanie, jeśli jedna z list będzie dłuższa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a1', 'b2', 'c3']\n"
     ]
    }
   ],
   "source": [
    "lista1 = ['a', 'b', 'c', 'd']\n",
    "lista2 = ['1', '2', '3']\n",
    "\n",
    "suma_list = [x+y for x, y in zip(lista1, lista2)]\n",
    "print(suma_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W analogiczny sposób zamiast list możemy tworzyć słowniki, używając *dictionary comprehension*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 1, 'b': 2, 'c': 3, 'd': 4}\n",
      "{'a': 1, 'c': 3}\n"
     ]
    }
   ],
   "source": [
    "keys = ['a', 'b', 'c', 'd']\n",
    "values = [1, 2, 3, 4]\n",
    "simple_dict = {key: value for key, value in zip(keys, values)} #wszystkie elementy dodane do słownika\n",
    "print(simple_dict) \n",
    "simple_odd_dict = {key: value for key, value in zip(keys, values) if value%2 != 0} #nieparzyste elementy \n",
    "                                                                                #dodane do słownika\n",
    "print(simple_odd_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Zapisywanie do plików\n",
    "\n",
    "Macierze i listy można zapisywać do pliku na wiele sposobów - można je zapisać jako plik możliwy do otworzenia w innych programach, np. .TXT,.CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = Path('zapisywanie_do_plikow_przyklady')\n",
    "os.makedirs(folder_path, exist_ok=True) #tworzymy folder, exist_ok - jeżeli taki istnieje, funkcja nie wyrzuca błędów\n",
    "\n",
    "np.savetxt(folder_path / 'parzyste.txt', parzyste, fmt='%d') #fmt='%d' - format, w jakim mają być zapisane dane, \n",
    "                                            #d oznacza liczby całkowite (integer), można zamiast tego użyć fmt='%i'\n",
    "pd.DataFrame(parzyste).to_csv(folder_path / 'parzyste.csv', index=False)\n",
    "\n",
    "#zapis listy, każdy element w nowej linii - można w ten sposób zapisywać do pliku .TXT string, np. nazwy plików\n",
    "with open(folder_path / 'lista1.txt', 'w') as text_file:\n",
    "    for element in lista1:\n",
    "        text_file.write(element+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Można też zapisać je do plików, których otwarcie będzie wymagało Pythona, np.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(folder_path / 'liczby_parzyste.npy', parzyste)\n",
    "pd.DataFrame(parzyste).to_hdf(folder_path / 'parzyste.h5', key='df', mode='w') #pliki HDF/.H5 są często używane do przechowywania zbiorów danych\n",
    "pickle.dump(parzyste, open(folder_path / 'parzyste_pickle','wb')) #wb oznacza write binary - zmienna parzyste zostanie zapisana do pliku binarnego"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Żeby wczytać pliki, które przed chwilą zapisaliśmy, należy użyć funkcji:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "parzyste_txt = np.loadtxt(folder_path / 'parzyste.txt')\n",
    "parzyste_csv = pd.read_csv(folder_path / 'parzyste.csv') #uwaga, wczyta się jako DataFrame\n",
    "parzyste_numpy = np.load(folder_path / 'liczby_parzyste.npy')\n",
    "parzyste_pickle = pickle.load(open(folder_path / \"parzyste_pickle\", 'rb')) #rb oznacza read binary\n",
    "parzyste_hdf = pd.read_hdf(folder_path / 'parzyste.h5', 'df')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wyświetl powyższe 4 zmienne i zobacz, czym różni się różnią"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Żeby wczytując z pliku .CSV lub HDF uzyskać zwykłą macierz, należy to zrobić w ten sposób:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "parzyste_csv = pd.read_csv(folder_path / 'parzyste.csv').to_numpy().flatten()\n",
    "parzyste_hdf = pd.read_hdf(folder_path / 'parzyste.h5', 'df').to_numpy().flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Warto zapamiętac bibliotekę `pickle` - jest szczególnie użyteczna, bo pozwala na zapisanie do pliku dowolnej struktury danych, również klasyfikatorów, sieci neuronowych i innych modeli, które będziemy tworzyć w trakcie semestru. Używa się jej zawsze w ten sam sposób, bez względu na to, co chcemy zapisać.\n",
    "\n",
    "Z tego samego powodu (możliwość zapisania dowolnej struktury obiektów) należy być ostrożnym przy otwieraniu plików w tym formacie z nieznanego źródła."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Biblioteka `os` i operacje na stringach\n",
    "\n",
    "Ostatnia część powtórki dotyczy użycia biblioteki os oraz operacji na stringach, które mogą się przydać do pracy na plikach.\n",
    "\n",
    "Dzięki bibliotece os jesteśmy w stanie np. utworzyć nowy folder (to już zrobiliśmy wyżej), wypisać listę wszystkich plików w danym folderze, strukturę folderów, utworzyć listę ścieżek dostępów do plików, które chcemy poddać analizie itp.\n",
    "\n",
    "Poniżej kilka przykładów użycia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zapisywanie_do_plikow_przyklady\n",
      "[]\n",
      "['parzyste.csv', 'lista1_renamed.txt', 'parzyste.h5', 'parzyste_pickle', 'parzyste_renamed.txt', 'lista1.txt', 'parzyste.txt', 'liczby_parzyste.npy']\n"
     ]
    }
   ],
   "source": [
    "#tworzenie listy ścieżek dostępu do plików, które znajdują się w folderze path = 'zapisywanie_do_plikow_przyklady/'\n",
    "paths_to_files = []\n",
    "for directory, subdirs, files in os.walk(folder_path):\n",
    "    print(directory) #nazwa folderu głównego\n",
    "    print(subdirs) #w tym przypadku pusta lista, ponieważ w folderze nie ma żadnych innych folderów\n",
    "    print(files) #lista plików w folderze\n",
    "    paths_to_files.extend([os.path.join(folder_path, file) for file in files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tworzenie listy plików o rozszerzeniu .TXT\n",
    "paths_to_txt_files = []\n",
    "for directory, subdirs, files in os.walk(folder_path):\n",
    "    paths_to_txt_files.extend([os.path.join(folder_path, file) for file in files if file.endswith('.txt')])\n",
    "\n",
    "#alternatywna metoda\n",
    "paths_to_txt_files = glob(os.path.join(folder_path, '**/*.txt'), recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zmiana nazwy plików\n",
    "for directory, subdirs, files in os.walk(folder_path):\n",
    "    for file in files:\n",
    "        if file.endswith('.txt'):\n",
    "            old_name = os.path.join(folder_path, file)\n",
    "            file_name, extension = os.path.splitext(file)\n",
    "            new_name = os.path.join(folder_path, f'{file_name}_renamed{extension}')\n",
    "            os.rename(old_name, new_name)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Użycie większości opisanych funkcji przećwiczymy w zadaniu Lab1_pierwszy_klasyfikator."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
